{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 체크포인트\n",
    "\n",
    "## 과적합(Overfitting)과 과소적합 (Underfitting)\n",
    "\n",
    "### 훈련 모형의 적합성\n",
    "- 훈련 데이터를 이용하여 학습을 수행할 때, 모형은 당연히 그 훈련 데이터에 대해서는 적합한 결과를 도출할 것\n",
    "- 이 모형이 검증 데이터에 대해서도 정확하게 예측해야만 일반화(generalization)가 잘 되었다고 판단\n",
    "- 또는, 훈련 데이터에 대해서 적합한 결과를 도출할 수 있는 정도의 학습이 이루어지지 않을 수도 \n",
    "- 설령 검증 데이터에 대해서 정확하게 예측한다고 하더라도 애초에 그 모형의 신뢰성은 높지 않을 것\n",
    "\n",
    "### 과적합 (Overfitting) 이란?\n",
    "- 훈련 데이터를 너무 지나치게 학습하여 학습 모형이 일반화되지 않은 상태\n",
    "- 훈련 데이터에 대해서만 너무 잘 맞춰져 있기 때문에, 학습되지 않은 다른 데이터에 대해서는 잘 대응되지 않는다\n",
    "![](../img/overfitting.png)\n",
    "\n",
    "#### 과대적합의 원인과 해결방안\n",
    "- 훈련 데이터의 특성에 비해 학습 모형이 너무 복잡한 경우\n",
    "    - 매개변수의 수가 적은 모형을 선택\n",
    "    - 모형에 규제(regularization)를 적용하여 단순화\n",
    "- 훈련 데이터의 특성이 특정값으로 편중된 경우 \n",
    "    - 훈련 데이터의 특성 값을 다양화\n",
    "- 훈련 데이터의 개수가 너무 적은 경우\n",
    "    - 더 많은 훈련 데이터를 확보\n",
    "- 훈련 데이터에 노이즈가 많은 경우\n",
    "    - 오류 데이터를 수정/삭제하거나 이상치(outlier)를 제거\n",
    "    \n",
    "#### 과대적합에 대한 규제 (Regularization)\n",
    "- **규제(regularization)** : 과대적합을 피하기 위해서 학습 모형을 단순화하고 제약을 가하는 것\n",
    "- 학습하는 동안 적용하는 규제의 수준은 **하이퍼파라미터(hyperparameter)**를 기반으로 결정되며, 학습을 수행하기 전에 미리 지정되어 훈련하는 동안에는 상수로 동작\n",
    "- 하이퍼파라미터의 값을 크게 지정할수록 복잡도가 낮은 모형을 추정\n",
    "    - 과대적합의 위험성을 감소\n",
    "    - 반면, 결과 모형의 설명력도 낮아질 수\n",
    "- 훈련 데이터의 수를 늘릴수록 더 잘 일반화\n",
    "- 규제를 적용하면 더 잘 일반화\n",
    "    \n",
    "---    \n",
    "    \n",
    "### 과소적합 (Underfitting) 이란?\n",
    "- 훈련 모형이 너무 단순하여 훈련 데이터의 특징을 잘 학습하지 못한 상태\n",
    "- 훈련 데이터조차 제대로 반영하지 못 하여 설명력이 낮기 때문에, 다른 데이터의 예측에 대한 신뢰성\n",
    "![](../img/underfitting.png)\n",
    "\n",
    "#### 과소적합의 원인과 해결방안\n",
    "- 훈련 데이터의 특성에 비해 학습 모형이 너무 단순한 경우\n",
    "    - 매개변수의 수가 더 많은 복잡한 모형을 선택하거나 새로운 특성을 추가\n",
    "- 학습 모형에 지나치게 규제가 많이 적용된 경우\n",
    "    - 모형에 적용되어 있는 제약을 줄어듬\n",
    "- 훈련 데이터 자체를 충분히 학습시키지 않은 경우\n",
    "    - 과대적합이 되기 전까지 충분히 오랫동안 (또는 반복하여) 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 편향-분산 트레이드오프\n",
    "\n",
    "### 편향 (Bias)\n",
    "- 데이터 또는 학습 모형이 얼마나 **특정한 방향으로 치우쳐져 있는가**를 의미\n",
    "- 학습 모형에서 예측값이 **정답과 멀리 있는 쪽으로 치우친 경향이 있을 때** 고편향(high bias)되어 있다고 표현\n",
    "- 편향은 낮을수록 좋음\n",
    "- 정답과 예측값들간의 관계\n",
    "\n",
    "### 분산 (Variance)\n",
    "- 데이터 또는 학습 모형이 얼마나 넒은 범위에 걸쳐 분포되어 있는가를 의미\n",
    "- 학습 모형에서 예측값이 서로 넓게 흩어져 있어서 변동성이 높을 때 고분산(high variance)되어 있다고 표현\n",
    "- 예측값들끼리의 관계\n",
    "\n",
    "![](../img/bias-variance-tradeoff.png)\n",
    "\n",
    "### 편향-분산 트레이드오프 (Bias-Variance Trade-off)\n",
    "- 일반적으로 편향과 분산 간에는 한 쪽이 높으면 나머지 한쪽이 낮아지는 경향\n",
    "- 즉, 편향이 높으면 분산이 낮아진다. (과소적합)\n",
    "- 반대로, 분산이 높으면 편향이 낮아진다. (과대적합)\n",
    "- **편향과 분산이 둘 다 동시에 최소화 되는 것은 일반적으로 불가능**하며, 이것을 `편향-분산 트레이드오프`라 함\n",
    "- 학습을 통해서 전체 오류가 최소화 되는 지점을 찾으면 그 시점에서의 추정된 모형이 가장 최적의 모형이 됨\n",
    "![](../img/bias-variance-tradeoff2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증 (Cross Validation)\n",
    "- 학습 모형의 성능을 확인하기 위해서는 검증 데이터가 필요\n",
    "- 전체 원본 데이터 중 일부를 골라서 검증 데이터로 사용하게 됨\n",
    "- 이 검증 데이터를 어떻게 선택하는가에 따라서 학습 모형의 성능이 달라질 수 있음\n",
    "- 따라서 검증 데이터의 편중을 막기 위해서 검증 데이터를 1종만 사용하지 않고 각각 다른 여러 종류의 검증 데이터를 선택하여 검증을 여러 차례 실시\n",
    "\n",
    "### K 폴드 (K-fold) 교차 검증\n",
    "데이터 집합을 K개의 부분집합(폴드)로 분리하여, (K–1)개의 폴드를 이용하여 학습을 수행하고 나머지 1개의 폴드를 이용하여 검증을 수행하는 과정을 K회 반복하는 검증 방식\n",
    "![](../img/k-fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런에서 K 폴드 교차 검증 수행\n",
    "\n",
    "#### model_selection 모듈에 있는 KFold를 이용하여 폴드를 분리할 객체를 생성\n",
    "- 첫 번째 매개변수 또는 n_splits는 분리할 폴드의 개수이다. 기본값은 3\n",
    "- 매개변수 shuffle은 데이터를 섞어서 분리할 것인지의 여부를 결정한다. 기본값은 False\n",
    "- 매개변수 random_state는 분리할 때마다 동일한 집합으로 생성할 것인지 결정하는 정수 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T07:26:20.861398Z",
     "start_time": "2019-07-17T07:26:20.858661Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "\n",
    "kfold = ms.KFold(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터를 준비하고 회귀 모형 객체를 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T07:26:21.199710Z",
     "start_time": "2019-07-17T07:26:21.181898Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as d\n",
    "import sklearn.linear_model as lm\n",
    "\n",
    "diab = d.load_diabetes()\n",
    "X = diab.data\n",
    "y = diab.target\n",
    "\n",
    "lr = lm.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold 객체의 split 함수를 호출하면 폴드 별 훈련 데이터 및 검증 데이터의 레코드 번호(즉, 행의 인덱스)들을 배열 형태로 반환한다. 이를 이용하여 폴드 별로 학습을 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T07:26:21.514427Z",
     "start_time": "2019-07-17T07:26:21.501145Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as mt\n",
    "n_iter = 0\n",
    "r2_scores = list()\n",
    "\n",
    "for train_num, test_num in kfold.split(X):\n",
    "    X_train, X_test = X[train_num], X[test_num]\n",
    "    y_train, y_test = y[train_num], y[test_num]\n",
    "    \n",
    "    reg = lr.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    r2_scores.append(mt.r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 개별 회차별 결정 계수와 전체 평균 결정 계수 값을 출력하여 검증 결과를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T07:28:00.168225Z",
     "start_time": "2019-07-17T07:28:00.162379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1회차 R2 Score : 0.429556\n",
      "2회차 R2 Score : 0.522598\n",
      "3회차 R2 Score : 0.482678\n",
      "4회차 R2 Score : 0.426508\n",
      "5회차 R2 Score : 0.550249\n",
      "평균 R2 Score :  0.4823181221114939\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(n_iter):\n",
    "    print(\"{}회차 R2 Score : {:3f}\".format(i+1,r2_scores[i]))\n",
    "print(\"평균 R2 Score : \", np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런에서 K 폴드 교차 검증 수행 (2)\n",
    "\n",
    "#### model_selection 모듈에 있는 cross_val_score 함수를 이용하여 K 폴드 교차 검증을 수행\n",
    "- 첫 번째 매개변수는 학습을 수행하는 객체이다.\n",
    "- 두 번째 매개변수는 데이터의 특성(독립변수) 집합이다.\n",
    "- 세 번째 매개변수는 데이터의 레이블(종속변수) 집합이다.\n",
    "- 매개변수 scoring은 성능 평가 지표 값을 적용할 함수 이름이다. 기본적으로는 명시할 필요 없다.\n",
    "- 매개변수 cv는 교차 검증을 수행할 폴드의 개수 또는 KFold 객체이다. 기본값은 폴드의 개수 3이다.\n",
    "- 반환 결과는 성능 평가 지표 값들이 들어 있는 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T07:44:14.934237Z",
     "start_time": "2019-07-17T07:44:14.901481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 회차별 R2 :  [0.42955643 0.52259828 0.4826784  0.42650827 0.55024923]\n",
      "평균 R2 :  0.4823181221114939\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as d\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.model_selection as ms\n",
    "import numpy as np\n",
    "\n",
    "diab = d.load_diabetes()\n",
    "X = diab.data\n",
    "y = diab.target\n",
    "lr = lm.LinearRegression()\n",
    "\n",
    "r2_scores = ms.cross_val_score(lr,X,y,cv=5)\n",
    "\n",
    "print(\"교차 검증 회차별 R2 : \",r2_scores)\n",
    "print(\"평균 R2 : \",np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 폴드 분리를 어떻게 하는가에 따라 검증 결과가 달라지고, 이에 따라 성능 지표 역시 변화하는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T07:48:49.890081Z",
     "start_time": "2019-07-17T07:48:49.860240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 회차별 R2 :  [0.40409355 0.52126938 0.54380392]\n",
      "평균 R2 :  0.4897222804616619\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as d\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.model_selection as ms\n",
    "import numpy as np\n",
    "\n",
    "diab = d.load_diabetes()\n",
    "lr = lm.LinearRegression()\n",
    "\n",
    "kfold = ms.KFold(3,shuffle=True,random_state=0)\n",
    "r2_scores = ms.cross_val_score(lr,diab.data,diab.target,cv=kfold)\n",
    "\n",
    "print(\"교차 검증 회차별 R2 : \",r2_scores)\n",
    "print(\"평균 R2 : \",np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고 : 매개변수 scoring\n",
    "- 함수 cross_val_score의 매개변수 scoring은 기본값으로 각 추정자 객체에 대해서 대표적인 성능 지표 함수가 자동적으로 호출\n",
    "    - • 예를 들어, LinearRegression의 경우 scoring의 기본값은 ‘r2’이며 metrics.r2_score를 호출\n",
    "- 이 함수를 다른 것으로 적용하고자 하는 경우에는 원하는 함수명을 직접 명시\n",
    "- 전체 scoring 이름과 대응하는 함수의 목록들은 [사이킷런 웹사이트](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)의 [Documentation]-[User Guide]-[3.3. Modelevaluation: quantifying the quality of predictions] 의 [3.3.1 The scoring parameter] 에서 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
